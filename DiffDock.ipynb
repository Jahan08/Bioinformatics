{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jahan08/Bioinformatics/blob/main/DiffDock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAH5NYgIWIlI"
      },
      "source": [
        "Use the [updated version now on github](https://colab.research.google.com/github/hgbrian/biocolabs/blob/master/DiffDock.ipynb).\n",
        "\n",
        "# DiffDock\n",
        "Dock a PDB files and a SMILES with [DiffDock](https://github.com/gcorso/DiffDock).\n",
        "\n",
        "Select Runtime / Run all to run an example PDB file and SMILES.\n",
        "\n",
        "v2 improvements:\n",
        "- works on proteins >1000 aas (with flag added to extract.py)\n",
        "- works on standard GPU (by reducing batch size from 10 to 6)\n",
        "- works with AlphaFold ids (AF-...) as well as PDB ids\n",
        "- works with comma-delimited PDB_ids and/or SMILES\n",
        "- runs smina to generate affinities (as DiffDock posed, or with smina minimization)\n",
        "- shows results in a py3DMol view\n",
        "\n",
        "v3:\n",
        "- fix py3dmol incompatibility\n",
        "- downgrade pytorch since the colab version takes forever to install pytorch_geometric (no binary so it has to compile)\n",
        "THIS MEANS YOU HAVE TO RUN ALL TWICE!\n",
        "\n",
        "v4:\n",
        "- replace smina with the more accurate gnina\n",
        "- remove the annoying run twice thing now there is a binary\n",
        "\n",
        "colab by [@btnaughton](https://twitter.com/btnaughton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M4xQfLgqWQsZ"
      },
      "outputs": [],
      "source": [
        "#@title PDB + SMILES input\n",
        "\n",
        "PDB_id = '4I8N' #@param {type:\"string\"}\n",
        "SMILES_or_pubchem_id = 'c1ccc2c(c1)nc(o2)C(Cc3ccc(cc3)NC(=O)C(=O)O)S(=O)(=O)Nc4ccc(cc4)F' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Download a tar file containing all results?\n",
        "download_results = True #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The default version of colab takes forever to install pytorch_geometric\n",
        "# For now, downgrade (which requires restarting runtime :( )\n",
        "#import os\n",
        "#import torch\n",
        "#if torch.__version__[:6] != \"1.13.1\":\n",
        "#    !pip uninstall torch torchaudio torchdata torchtext torchvision fastai --y\n",
        "#    !pip install torch==1.13.1\n",
        "#    os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "2NDRgVfVbnw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2Ssuid52VT-i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "from random import random\n",
        "\n",
        "def download_pdb_file(pdb_id: str) -> str:\n",
        "    \"\"\"Download pdb file as a string from rcsb.org\"\"\"\n",
        "    PDB_DIR =\"/tmp/pdb/\"\n",
        "    os.makedirs(PDB_DIR, exist_ok=True)\n",
        "\n",
        "    # url or pdb_id\n",
        "    if pdb_id.startswith('http'):\n",
        "        url = pdb_id\n",
        "        filename = url.split('/')[-1]\n",
        "    elif pdb_id.endswith(\".pdb\"):\n",
        "        return pdb_id\n",
        "    else:\n",
        "        if pdb_id.startswith(\"AF\"):\n",
        "            url = f\"https://alphafold.ebi.ac.uk/files/{pdb_id}-model_v3.pdb\"\n",
        "        else:\n",
        "            url = f\"http://files.rcsb.org/view/{pdb_id}.pdb\"\n",
        "        filename = f'{pdb_id}.pdb'\n",
        "\n",
        "    cache_path = os.path.join(PDB_DIR, filename)\n",
        "    if os.path.exists(cache_path):\n",
        "        return cache_path\n",
        "\n",
        "    pdb_req = requests.get(url)\n",
        "    pdb_req.raise_for_status()\n",
        "    open(cache_path, 'w').write(pdb_req.text)\n",
        "    return cache_path\n",
        "\n",
        "def download_smiles_str(pubchem_id: str, retries:int = 2) -> str:\n",
        "    \"\"\"Given a pubchem id, get a smiles string\"\"\"\n",
        "    while True:\n",
        "        req = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/CID/{pubchem_id}/property/CanonicalSMILES/CSV\")\n",
        "        smiles_url_csv = req.text if req.status_code == 200 else None\n",
        "        if smiles_url_csv is not None:\n",
        "            break\n",
        "        if retries == 0:\n",
        "            return None\n",
        "        time.sleep(1+random())\n",
        "        retries -= 1\n",
        "\n",
        "    return smiles_url_csv.splitlines()[1].split(',')[1].strip('\"').strip(\"'\") if smiles_url_csv is not None else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BYTBennzXxb1"
      },
      "outputs": [],
      "source": [
        "if not PDB_id or not SMILES_or_pubchem_id:\n",
        "    PDB_id = \"6agt\"\n",
        "    SMILES_or_pubchem_id = \"COc(cc1)ccc1C#N\"\n",
        "    print(f\"No input supplied. Using example data: {PDB_id} and {SMILES_or_pubchem_id}\")\n",
        "\n",
        "# to run many PDB+smiles at once, fill in a list of PDB_files and smiles here...\n",
        "pdb_files = [download_pdb_file(_PDB_id) for _PDB_id in PDB_id.split(\",\")]\n",
        "smiless = [download_smiles_str(_SMILES_or_pubchem_id) if str(_SMILES_or_pubchem_id).isnumeric() else _SMILES_or_pubchem_id\n",
        "           for _SMILES_or_pubchem_id in SMILES_or_pubchem_id.split(',') ]\n",
        "\n",
        "with open(\"/tmp/input_protein_ligand.csv\", 'w') as out:\n",
        "    out.write(\"protein_path,ligand\\n\")\n",
        "    for pdb_file in pdb_files:\n",
        "        for smiles in smiless:\n",
        "            out.write(f\"{pdb_file},{smiles}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ptul2hJM2HmA"
      },
      "outputs": [],
      "source": [
        "# clear out old results if running multiple times -- hopefully they have been downloaded already\n",
        "!rm -rf /content/DiffDock/results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9PwzHUWDlj"
      },
      "source": [
        "## Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FSbikKk6fXAu",
        "outputId": "be2b241a-2fd5-4556-d953-f782b2c14978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.3/1.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 342 µs (started: 2023-09-25 16:24:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime --quiet\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hTQPGM8ptbRy",
        "outputId": "e19ea778-e28e-488f-b4c0-906b8ade3fbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'DiffDock'...\n",
            "remote: Enumerating objects: 305, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 305 (delta 127), reused 104 (delta 104), pack-reused 147\u001b[K\n",
            "Receiving objects: 100% (305/305), 232.37 MiB | 21.35 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n",
            "Updating files: 100% (56/56), done.\n",
            "/content/DiffDock\n",
            "Note: switching to 'a6c5275'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at a6c5275 remove debugging raise in the inference file\n",
            "time: 14.4 s (started: 2023-09-25 16:24:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"/content/DiffDock\"):\n",
        "    %cd /content\n",
        "    !git clone https://github.com/gcorso/DiffDock.git\n",
        "    %cd /content/DiffDock\n",
        "    !git checkout a6c5275 # remove/update for more up to date code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0vSCAwwrtdr8",
        "outputId": "e1dc474e-da65-48b6-91a7-3d729449a7e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pkgtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 1min 9s (started: 2023-09-25 16:25:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import biopandas\n",
        "except:\n",
        "    !pip install pyg==0.7.1 --quiet\n",
        "    !pip install pyyaml==6.0 --quiet\n",
        "    !pip install scipy==1.7.3 --quiet\n",
        "    !pip install networkx==2.6.3 --quiet\n",
        "    !pip install biopython==1.79 --quiet\n",
        "    !pip install rdkit-pypi==2022.03.5 --quiet\n",
        "    !pip install e3nn==0.5.0 --quiet\n",
        "    !pip install spyrmsd==0.5.2 --quiet\n",
        "    !pip install pandas==1.5.3 --quiet\n",
        "    !pip install biopandas==0.4.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RZ9qNmHcLMX",
        "outputId": "1540c3c9-392d-43ea-d84a-339bb1774ce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "Found existing installation: torch-scatter 2.1.1+pt20cu118\n",
            "Uninstalling torch-scatter-2.1.1+pt20cu118:\n",
            "  Successfully uninstalled torch-scatter-2.1.1+pt20cu118\n",
            "Found existing installation: torch-sparse 0.6.17+pt20cu118\n",
            "Uninstalling torch-sparse-0.6.17+pt20cu118:\n",
            "  Successfully uninstalled torch-sparse-0.6.17+pt20cu118\n",
            "\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch-cluster 1.6.1+pt20cu118\n",
            "Uninstalling torch-cluster-1.6.1+pt20cu118:\n",
            "  Successfully uninstalled torch-cluster-1.6.1+pt20cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install git+https://github.com/pyg-team/pytorch_geometric.git  --quiet # @ 15573f4674b2a37b1b9adc967df69ef6eee573ea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpIBFqW7eNC7"
      },
      "source": [
        "## Install ESM and prepare PDB file for ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2lduAr-WWPyX",
        "outputId": "014ec015-6ffd-4f08-f543-99e20dc9a71a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DiffDock\n",
            "Cloning into 'esm'...\n",
            "remote: Enumerating objects: 1511, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 1511 (delta 42), reused 126 (delta 36), pack-reused 1360\u001b[K\n",
            "Receiving objects: 100% (1511/1511), 11.78 MiB | 10.13 MiB/s, done.\n",
            "Resolving deltas: 100% (891/891), done.\n",
            "/content/DiffDock/esm\n",
            "Note: switching to 'ca8a710'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at ca8a710 Update version.py (#310)\n",
            "Obtaining file:///content/DiffDock/esm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 73, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 491, in collect_root_requirements\n",
            "    req = self._make_requirement_from_install_req(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 453, in _make_requirement_from_install_req\n",
            "    cand = self._make_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    self._editable_candidate_cache[link] = EditableCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 328, in _prepare_distribution\n",
            "    return self._factory.preparer.prepare_editable_requirement(self._ireq)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 687, in prepare_editable_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 69, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/distributions/sdist.py\", line 38, in prepare_distribution_metadata\n",
            "    self._prepare_build_backend(finder)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/distributions/sdist.py\", line 70, in _prepare_build_backend\n",
            "    self.req.build_env.install_requirements(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 217, in install_requirements\n",
            "    self._install_requirements(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 275, in _install_requirements\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 73, in emit\n",
            "    if self.shouldRollover(record):\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 191, in shouldRollover\n",
            "    if os.path.exists(self.baseFilename) and not os.path.isfile(self.baseFilename):\n",
            "  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "/content/DiffDock\n",
            "time: 7.66 s (started: 2023-09-25 16:34:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"/content/DiffDock/esm\"):\n",
        "    %cd /content/DiffDock\n",
        "    !git clone https://github.com/facebookresearch/esm\n",
        "    %cd /content/DiffDock/esm\n",
        "    !git checkout ca8a710 # remove/update for more up to date code\n",
        "    !sudo pip install -e .\n",
        "    %cd /content/DiffDock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbxUtRgHwoIx"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "!python datasets/esm_embedding_preparation.py --protein_ligand_csv /tmp/input_protein_ligand.csv --out_file data/prepared_for_esm.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKUU2PKDxTkX"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "%env HOME=esm/model_weights\n",
        "%env PYTHONPATH=$PYTHONPATH:/content/DiffDock/esm\n",
        "!python /content/DiffDock/esm/scripts/extract.py esm2_t33_650M_UR50D data/prepared_for_esm.fasta data/esm2_output --repr_layers 33 --include per_tok --truncation_seq_length 30000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJTXj5SeYzG"
      },
      "source": [
        "## Run DiffDock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D5gqUcabTAg"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "!python -m inference --protein_ligand_csv /tmp/input_protein_ligand.csv --out_dir results/user_predictions_small --inference_steps 20 --samples_per_complex 40 --batch_size 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlPOKLIBsiPU"
      },
      "source": [
        "# Post-process and download results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqWHbQdeXbe0"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "!wget https://sourceforge.net/projects/smina/files/smina.static/download -O smina && chmod +x smina\n",
        "!wget https://github.com/gnina/gnina/releases/download/v1.0.3/gnina -O gnina && chmod +x gnina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpjCe9IWjz5M"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from shlex import quote\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "%cd /content/DiffDock/results/user_predictions_small\n",
        "results_dirs = glob(\"./index*\")\n",
        "\n",
        "rows = []\n",
        "for results_dir in tqdm(results_dirs, desc=\"runs\"):\n",
        "    results_pdb_file = \"/tmp/pdb/\" + re.findall(\"tmp-pdb-(.+\\.pdb)\", results_dir)[0]\n",
        "    results_smiles = re.findall(\"pdb_+(.+)\", results_dir)[0]\n",
        "    results_sdfs = [os.path.join(results_dir, f) for f in os.listdir(results_dir) if \"confidence\" in f and f.endswith(\".sdf\")]\n",
        "\n",
        "    results_pdb_file_no_hetatms = f\"{results_pdb_file}_nohet.pdb\"\n",
        "    !grep -v \"^HETATM\" {results_pdb_file} > {results_pdb_file_no_hetatms}\n",
        "    !cp {results_pdb_file} .\n",
        "\n",
        "    for results_sdf in tqdm(results_sdfs, leave=False, desc=\"files\"):\n",
        "        confidence = re.findall(\"confidence([\\-\\.\\d]+)\\.sdf\", results_sdf)[0]\n",
        "\n",
        "        scored_stdout = !/content/DiffDock/gnina --score_only -r \"{results_pdb_file_no_hetatms}\" -l \"{results_sdf}\"\n",
        "        scored_affinity = re.findall(\"Affinity:\\s*([\\-\\.\\d+]+)\", '\\n'.join(scored_stdout))[0]\n",
        "        minimized_stdout = !/content/DiffDock/gnina --local_only --minimize -r \"{results_pdb_file_no_hetatms}\" -l \"{results_sdf}\" --autobox_ligand \"{results_sdf}\" --autobox_add 2\n",
        "        minimized_affinity = re.findall(\"Affinity:\\s*([\\-\\.\\d+]+)\", '\\n'.join(minimized_stdout))[0]\n",
        "\n",
        "        rows.append((results_pdb_file.split('/')[-1], results_smiles, float(confidence), float(scored_affinity), float(minimized_affinity), results_sdf))\n",
        "\n",
        "#\n",
        "# create dataframe, tar file and download\n",
        "#\n",
        "df_results = pd.DataFrame(rows, columns=[\"pdb_file\", \"smiles\", \"diffdock_confidence\", \"gnina_scored_affinity\", \"gnina_minimized_affinity\", \"sdf_file\"])\n",
        "df_results_tsv = \"df_diffdock_results.tsv\"\n",
        "df_results.to_csv(df_results_tsv, sep='\\t', index=None)\n",
        "\n",
        "out_pdbs = ' '.join(set(df_results.pdb_file.apply(quote)))\n",
        "out_sdfs = ' '.join(df_results.sdf_file.apply(quote))\n",
        "\n",
        "if download_results:\n",
        "    tarname = f\"diffdock_{datetime.now().isoformat()[2:10].replace('-','')}\"\n",
        "    _ = !tar cvf {tarname}.tar --transform 's,^,{tarname}/,' --transform 's,\\./,,' {out_pdbs} {out_sdfs} {df_results_tsv}\n",
        "\n",
        "    files.download(f\"{tarname}.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIgH3MSt_dWx"
      },
      "source": [
        "## Compare gnina affinities with DiffDock confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqNY2KK-Xn3t"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "for (pdb_file, smiles), df_group in df_results.groupby([\"pdb_file\", \"smiles\"]):\n",
        "    f, ax = plt.subplots(1, 2, figsize=(20,8))\n",
        "    sns.regplot(data=df_group, x=\"diffdock_confidence\", y=\"gnina_scored_affinity\", ax=ax[0]);\n",
        "    sns.regplot(data=df_group, x=\"diffdock_confidence\", y=\"gnina_minimized_affinity\", ax=ax[1]);\n",
        "\n",
        "    slope, intercept, r_value_scored, p_value, std_err = linregress(df_group[\"diffdock_confidence\"], df_group[\"gnina_scored_affinity\"])\n",
        "    slope, intercept, r_value_minimized, p_value, std_err = linregress(df_group[\"diffdock_confidence\"], df_group[\"gnina_minimized_affinity\"])\n",
        "    ax[0].set_title(f\"{pdb_file} {smiles[:30]} gnina scored r={r_value_scored:.3f}\");\n",
        "    ax[1].set_title(f\"{pdb_file} {smiles[:30]} gnina minimized r={r_value_minimized:.3f}\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB3C-Bn0o9En"
      },
      "outputs": [],
      "source": [
        "df_results.sort_values(\"diffdock_confidence\", ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbeaGfBEAn3D"
      },
      "source": [
        "# Visualize top hit (highest confidence) in 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmgFz0PIYqJA"
      },
      "outputs": [],
      "source": [
        "!pip install py3dmol==2.0.3 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCwsUBpmYof5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "import py3Dmol\n",
        "\n",
        "resid_hover = \"\"\"\n",
        "function(atom,viewer) {\n",
        "    if(!atom.label) {\n",
        "        atom.label = viewer.addLabel(atom.chain+\" \"+atom.resn+\" \"+atom.resi,\n",
        "            {position: atom, backgroundColor: 'mintcream', fontColor:'black', fontSize:12});\n",
        "    }\n",
        "}\"\"\"\n",
        "unhover_func = \"\"\"\n",
        "function(atom,viewer) {\n",
        "    if(atom.label) {\n",
        "        viewer.removeLabel(atom.label);\n",
        "        delete atom.label;\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "view = py3Dmol.view(width=800, height=800)\n",
        "view.setCameraParameters({'fov': 35, 'z': 100});\n",
        "\n",
        "# top hit for any pdb file and any smiles\n",
        "top_hit = df_results.sort_values(\"diffdock_confidence\", ascending=False).iloc[0]\n",
        "print(\"top hit:\")\n",
        "display(top_hit)\n",
        "\n",
        "# add sdf\n",
        "view.addModel(open(top_hit.sdf_file).read(), \"sdf\")\n",
        "view.setStyle({\"model\": 0}, {'stick':{\"color\":\"#ff0000\"}})\n",
        "view.setViewStyle({\"model\": 0}, {'style':'outline','color':'black','width':0.1})\n",
        "view.zoomTo();\n",
        "\n",
        "# add pdb\n",
        "view.addModel(open(top_hit.pdb_file).read(), \"pdb\");\n",
        "view.setStyle({\"model\": 1}, {\"cartoon\":{\"color\":\"spectrum\"}})\n",
        "view.setStyle({\"model\": 1, \"hetflag\":True}, {'stick':{\"color\":\"spectrum\"}})\n",
        "\n",
        "model = view.getModel()\n",
        "model.setHoverable({}, True, resid_hover, unhover_func)\n",
        "\n",
        "view"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}