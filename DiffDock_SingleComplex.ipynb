{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jahan08/Bioinformatics/blob/main/DiffDock_SingleComplex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DiffDock\n",
        "Dock a small molecules on to protein structures using DiffDock approach\n",
        "\n",
        "1.   This notebook allows you to run diffdock on single protein/ligands and also multiple proteins/ligands.\n",
        "\n",
        "2.   Colab basic version works fine with single simulations. \"Premium GPU\" (colab pro), and even then it may fail on large complexes.\n",
        "\n",
        "## References:\n",
        "\n",
        "[Research Article](https://arxiv.org/abs/2210.01776)\n",
        "\n",
        "[Github](https://github.com/gcorso/DiffDock)\n",
        "\n",
        "[Interactive Online tool by Simon Duerr](https://huggingface.co/spaces/simonduerr/diffdock)\n",
        "\n",
        "[Colab Notebook by Brian Naughton](https://colab.research.google.com/drive/1nvCyQkbO-TwXZKJ0RCShVEym1aFWxlkX). The current notebook revised from Brain's work/code.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s4ov_2_SdX8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with mapping Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE1D_307TPZc",
        "outputId": "44cf24aa-3b8a-4c28-99aa-c588cc0ce98d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**: Setup working directory named \"DiffDock_V2\" in your Google Drive and update directory path.\n",
        "\n",
        "Copy or move this colab notebook to the current directory."
      ],
      "metadata": {
        "id": "8wsKRnvhMqSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enable this code inorder to create DiffDock_V2 directory\n",
        "#Pls ignore this step if you have already created one\n",
        "%cd /content/drive/MyDrive\n",
        "%mkdir DiffDock_V2\n",
        "%cd DiffDock_V2\n",
        "%ls"
      ],
      "metadata": {
        "id": "tMtmKxmNbC3N",
        "outputId": "cba66159-51fe-4ed5-c2fe-c617b37928dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/DiffDock_V2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have already created or would like to work on different directory; please update the path accordingly"
      ],
      "metadata": {
        "id": "Av8ynSKRb3zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DiffDock_V2\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOUZ0HWiiGPg",
        "outputId": "522b497c-2d1a-4148-9668-d3d57e55f5be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAH5NYgIWIlI"
      },
      "source": [
        "## Step 2:\n",
        "Install the dependencies for DiffDock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9PwzHUWDlj"
      },
      "source": [
        "## Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FSbikKk6fXAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da668ca0-93e4-403e-b3fb-eec6acb73dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.19.0\n",
            "time: 462 µs (started: 2023-09-25 17:41:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hTQPGM8ptbRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9527ce0d-570c-4f5c-d6c3-8c746e832327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2\n",
            "Cloning into 'DiffDock'...\n",
            "remote: Enumerating objects: 305, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 305 (delta 127), reused 104 (delta 104), pack-reused 147\u001b[K\n",
            "Receiving objects: 100% (305/305), 232.37 MiB | 14.07 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n",
            "Updating files: 100% (56/56), done.\n",
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n",
            "Note: switching to '0f9c419'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 0f9c419 improve README\n",
            "time: 21.5 s (started: 2023-09-25 17:42:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DiffDock_V2\n",
        "!git clone https://github.com/gcorso/DiffDock.git\n",
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock\n",
        "!git checkout 0f9c419 # remove/update for more up to date code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0vSCAwwrtdr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b52350-5f57-44b8-c1ba-8c7ced3fb29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.4/65.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pkgtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.12.3 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.12.1+cu113 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.12.1+cu113\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nglview (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "time: 2min 15s (started: 2023-09-25 17:43:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyg==0.7.1 --quiet\n",
        "!pip install pyyaml==6.0 --quiet\n",
        "!pip install scipy==1.7.3 --quiet\n",
        "!pip install networkx==2.6.3 --quiet\n",
        "!pip install biopython==1.79 --quiet\n",
        "!pip install rdkit-pypi==2022.03.5 --quiet\n",
        "!pip install e3nn==0.5.0 --quiet\n",
        "!pip install spyrmsd==0.5.2 --quiet\n",
        "!pip install pandas==1.3.5 --quiet\n",
        "!pip install biopandas==0.4.1 --quiet\n",
        "!pip install torch==1.12.1+cu113 --quiet\n",
        "!pip install nglview --quiet\n",
        "!pip install -q nglview pytraj --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_RZ9qNmHcLMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f8f0e2-0114-4d0a-efbc-88529d890b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "time: 46.8 s (started: 2023-09-25 17:45:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install git+https://github.com/pyg-team/pytorch_geometric.git  --quiet # no version for some reason??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgNOaZ3YdKsg"
      },
      "source": [
        "### Download 2GB PDBBind dataset\n",
        "unnecessary for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e72N-MyCuN8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970dc2c5-cc2f-42f5-f793-ee8f77a3fb64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.54 ms (started: 2022-10-24 01:37:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#!test -d /content/DiffDock/data/PDBBind_processed || (wget https://zenodo.org/record/6034088/files/PDBBind.zip && unzip -q PDBBind.zip && mv PDBBind_processed /content/DiffDock/data/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Input files\n",
        "\n"
      ],
      "metadata": {
        "id": "OJMaJ969h8Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:**\n",
        "\n",
        "1.   Upload protein and ligand file in data directory.\n",
        "2.   DiffDock supports .pdb file format for protein\n",
        "3.   and it supports, .sdf or .mol2, and SMILES format for ligand\n",
        "4.   For example, i have saved protein as 'protein.pdb' and ligand as 'ligand.sdf'.\n",
        "5.   Update the respective file names in esm embedding preparation and inference steps.\n",
        "6.   Alternatively, you can also provide SMILES as an input. For example, **--ligand \"COc(cc1)ccc1C#N\"** instead of *--ligand ligand.sdf*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5dUfLI9pXSNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "8bNlEvK8PJmV",
        "outputId": "a5f14b18-53d5-414d-f3e1-2facaf678e0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/data'\n",
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5effcadf-a5b4-41c3-b902-a3c12ef23917\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5effcadf-a5b4-41c3-b902-a3c12ef23917\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1CG_ideal.sdf to 1CG_ideal.sdf\n",
            "time: 8.89 s (started: 2023-09-25 17:50:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For demo files refer my [github profile](https://github.com/suneelbvs/DiffDock)"
      ],
      "metadata": {
        "id": "LA0e0STv3nNC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpIBFqW7eNC7"
      },
      "source": [
        "## Install ESM and prepare PDB file for ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2lduAr-WWPyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b3f758-8d4f-4ee9-a7ad-6df8fd136589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n",
            "Cloning into 'esm'...\n",
            "remote: Enumerating objects: 1511, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 1511 (delta 42), reused 126 (delta 36), pack-reused 1360\u001b[K\n",
            "Receiving objects: 100% (1511/1511), 11.78 MiB | 10.28 MiB/s, done.\n",
            "Resolving deltas: 100% (891/891), done.\n",
            "Updating files: 100% (476/476), done.\n",
            "/content/drive/MyDrive/DiffDock_V2/DiffDock/esm\n",
            "error: Your local changes to the following files would be overwritten by checkout:\n",
            "\texamples/lm-design/paper-data/artificial_sequence_purge_ids.txt\n",
            "\texamples/lm-design/paper-data/uniref90_jackhmmer_purge_ids.txt\n",
            "Please commit your changes or stash them before you switch branches.\n",
            "Aborting\n",
            "Obtaining file:///content/drive/MyDrive/DiffDock_V2/DiffDock/esm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fair-esm\n",
            "  Building editable for fair-esm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fair-esm: filename=fair_esm-2.0.1-0.editable-py3-none-any.whl size=17871 sha256=5fac21294447f4fed04ae0975634c4507f522f0bfd17d379f5ea335a21638999\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v1uyf6io/wheels/25/4c/57/b040ca0adf870a89af5d8f49167dddf19916ccee0c38d4d003\n",
            "Successfully built fair-esm\n",
            "Installing collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.1\n",
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n",
            "time: 23.3 s (started: 2023-09-25 17:50:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock\n",
        "!git clone https://github.com/facebookresearch/esm\n",
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock/esm\n",
        "!git checkout f07aed6 # remove/update for more up to date code\n",
        "!sudo pip install -e .\n",
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qbxUtRgHwoIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38cdfd5-722a-4a11-fbc1-bd51b3c03614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n",
            "100% 1/1 [00:00<00:00, 12.19it/s]\n",
            "time: 1.32 s (started: 2023-09-25 17:51:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock\n",
        "!python datasets/esm_embedding_preparation.py --protein_path /content/drive/MyDrive/DiffDock_V2/DiffDock/data/protein.pdb --out_file data/prepared_for_esm.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKUU2PKDxTkX",
        "outputId": "fe631566-4cfe-4932-d195-2edcc7b97501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n",
            "env: HOME=esm/model_weights\n",
            "env: PYTHONPATH=$PYTHONPATH:/content/drive/MyDrive/DiffDock_V2/DiffDock/esm\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to esm/model_weights/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to esm/model_weights/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n",
            "Read data/prepared_for_esm.fasta with 1 sequences\n",
            "Processing 1 of 1 batches (1 sequences)\n",
            "time: 1min 11s (started: 2023-09-25 17:51:47 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock\n",
        "%env HOME=esm/model_weights\n",
        "%env PYTHONPATH=$PYTHONPATH:/content/drive/MyDrive/DiffDock_V2/DiffDock/esm\n",
        "!python /content/drive/MyDrive/DiffDock_V2/DiffDock/esm/scripts/extract.py esm2_t33_650M_UR50D data/prepared_for_esm.fasta data/esm2_output --repr_layers 33 --include per_tok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJTXj5SeYzG"
      },
      "source": [
        "## Run DiffDock"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DiffDock_V2/DiffDock\n",
        "!python -m inference --protein_path data/protein.pdb --ligand data/ligand.sdf --out_dir results/singlecomplx --inference_steps 20 --samples_per_complex 40 --batch_size 10 --actual_steps 18 --no_final_step_noise\n",
        "#!mv 'index0_data-testing-6w70.pdb____data-testing-6w70_ligand.sdf' out #update the folder name, if you provide custom names for inputs\n",
        "#%cd ./out\n",
        "#%ls"
      ],
      "metadata": {
        "id": "LLMDimzDWWqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcde041-951d-4d95-b6a8-17ef6ec5b9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2/DiffDock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVn2g1AcdPaM"
      },
      "source": [
        "## Download results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./results/singlecomplx\n",
        "!mv 'index0_data-protein.pdb____data-ligand.sdf' out\n",
        "#%cp ./data/*.*pdb\n",
        "%cd ./out\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLpm-a_trP1Z",
        "outputId": "d0894444-2a0b-4899-c849-8b86a0c7153b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DiffDock_V2/DiffDock/results/singlecomplx\n",
            "/content/drive/MyDrive/DiffDock_V2/DiffDock/results/singlecomplx/out\n",
            "rank10_confidence0.01.sdf   rank29_confidence-1.25.sdf\n",
            "rank11_confidence0.00.sdf   rank2_confidence0.38.sdf\n",
            "rank12_confidence-0.08.sdf  rank30_confidence-1.33.sdf\n",
            "rank13_confidence-0.14.sdf  rank31_confidence-1.33.sdf\n",
            "rank14_confidence-0.21.sdf  rank32_confidence-1.47.sdf\n",
            "rank15_confidence-0.24.sdf  rank33_confidence-1.53.sdf\n",
            "rank16_confidence-0.26.sdf  rank34_confidence-1.64.sdf\n",
            "rank17_confidence-0.27.sdf  rank35_confidence-1.93.sdf\n",
            "rank18_confidence-0.31.sdf  rank36_confidence-2.18.sdf\n",
            "rank19_confidence-0.35.sdf  rank37_confidence-2.87.sdf\n",
            "rank1_confidence0.44.sdf    rank38_confidence-2.96.sdf\n",
            "rank1.sdf                   rank39_confidence-3.29.sdf\n",
            "rank20_confidence-0.36.sdf  rank3_confidence0.38.sdf\n",
            "rank21_confidence-0.44.sdf  rank40_confidence-3.41.sdf\n",
            "rank22_confidence-0.45.sdf  rank4_confidence0.37.sdf\n",
            "rank23_confidence-0.50.sdf  rank5_confidence0.36.sdf\n",
            "rank24_confidence-0.52.sdf  rank6_confidence0.34.sdf\n",
            "rank25_confidence-0.60.sdf  rank7_confidence0.30.sdf\n",
            "rank26_confidence-0.63.sdf  rank8_confidence0.06.sdf\n",
            "rank27_confidence-0.77.sdf  rank9_confidence0.06.sdf\n",
            "rank28_confidence-0.84.sdf\n",
            "time: 283 ms (started: 2022-10-24 02:12:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "13Rg9T7Sa-1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55106ede-efac-4fc5-f5d2-4beb26be68f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4 ms (started: 2022-10-24 01:40:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdPxZZGFxRXi",
        "outputId": "57f5eef3-e899-4e60-9868-e66e94189ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rank10_confidence0.01.sdf   rank29_confidence-1.25.sdf\n",
            "rank11_confidence0.00.sdf   rank2_confidence0.38.sdf\n",
            "rank12_confidence-0.08.sdf  rank30_confidence-1.33.sdf\n",
            "rank13_confidence-0.14.sdf  rank31_confidence-1.33.sdf\n",
            "rank14_confidence-0.21.sdf  rank32_confidence-1.47.sdf\n",
            "rank15_confidence-0.24.sdf  rank33_confidence-1.53.sdf\n",
            "rank16_confidence-0.26.sdf  rank34_confidence-1.64.sdf\n",
            "rank17_confidence-0.27.sdf  rank35_confidence-1.93.sdf\n",
            "rank18_confidence-0.31.sdf  rank36_confidence-2.18.sdf\n",
            "rank19_confidence-0.35.sdf  rank37_confidence-2.87.sdf\n",
            "rank1_confidence0.44.sdf    rank38_confidence-2.96.sdf\n",
            "rank1.sdf                   rank39_confidence-3.29.sdf\n",
            "rank20_confidence-0.36.sdf  rank3_confidence0.38.sdf\n",
            "rank21_confidence-0.44.sdf  rank40_confidence-3.41.sdf\n",
            "rank22_confidence-0.45.sdf  rank4_confidence0.37.sdf\n",
            "rank23_confidence-0.50.sdf  rank5_confidence0.36.sdf\n",
            "rank24_confidence-0.52.sdf  rank6_confidence0.34.sdf\n",
            "rank25_confidence-0.60.sdf  rank7_confidence0.30.sdf\n",
            "rank26_confidence-0.63.sdf  rank8_confidence0.06.sdf\n",
            "rank27_confidence-0.77.sdf  rank9_confidence0.06.sdf\n",
            "rank28_confidence-0.84.sdf\n",
            "time: 136 ms (started: 2022-10-24 02:22:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Work In Progress: Analysis Part\n",
        "**bold text**\n",
        "\n"
      ],
      "metadata": {
        "id": "X1_mWbA322rx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}