{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jahan08/Bioinformatics/blob/main/PepMLM_650M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PepMLM: Target Sequence-Conditioned Generation of Peptide Binders via Masked Language Modeling**\n",
        "\n",
        "Target proteins that lack accessible binding pockets and conformational stability have posed increasing challenges for drug development. Induced proximity strategies, such as PROTACs and molecular glues, have thus gained attention as pharmacological alternatives, but still require small molecule docking at binding pockets for targeted protein degradation (TPD). The computational design of protein-based binders presents unique opportunities to access “undruggable” targets, but have often relied on stable 3D structures or predictions for effective binder generation. Recently, we have leveraged the expressive latent spaces of protein language models (pLMs) for the prioritization of peptide binders from sequence alone, which we have then fused to E3 ubiquitin ligase domains, creating a CRISPR-analogous TPD system for target proteins. However, our methods rely on training discriminator models for ranking heuristically or unconditionally-derived “guide” peptides for their target binding capability. In this work, we introduce PepMLM, a purely target sequence-conditioned de novo generator of linear peptide binders. By employing a novel masking strategy that uniquely positions cognate peptide sequences at the terminus of target protein sequences, PepMLM tasks the state-of-the-art ESM-2 pLM to fully reconstruct the binder region, achieving low perplexities matching or improving upon previously-validated peptide-protein sequence pairs. After successful in silico benchmarking with AlphaFold-Multimer, we experimentally verify PepMLM’s efficacy via fusion of model-derived peptides to E3 ubiquitin ligase domains, demonstrating endogenous degradation of target substrates in cellular models. In total, PepMLM enables the generative design of candidate binders to any target protein, without the requirement of target structure, empowering downstream programmable proteome editing applications.     \n"
      ],
      "metadata": {
        "id": "ryL5IX7phfA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply for Access\n",
        "As of February 2024, the model has been gated on HuggingFace. If you wish to use our model, please visit our page on the HuggingFace site ([Link](https://huggingface.co/ChatterjeeLab/PepMLM-650M)) and submit your access request there. An active HuggingFace account is necessary for both the application and subsequent modeling use. Approval of requests may take a few days, as we are a small lab with a manual approval process.\n",
        "\n",
        "Once your request is approved, please input your personal access token below to begin using this notebook. We appreciate your understanding.\n",
        "\n",
        "- How to find your access token: https://huggingface.co/docs/hub/en/security-tokens"
      ],
      "metadata": {
        "id": "cOmrA9IR2_Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Packages\n",
        "! pip install Bio\n",
        "! pip install transformers\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "import io"
      ],
      "metadata": {
        "id": "HxMlwm4nuo9G",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input HF token\n",
        "! pip install -U \"huggingface_hub[cli]\"\n",
        "! huggingface-cli login"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EPjpRXoh5DyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inputs and Parameters\n",
        "\n",
        "#@markdown <font size = 4> How many sequences do you have?\n",
        "\n",
        "#@markdown <font size = 3> If you only have one sequence, check off the box below and provide your sequence.\n",
        "single_sequence = True #@param {type:\"boolean\"}\n",
        "protein_seq = \"FAMQMAYRF\" #@param {type:\"string\"}\n",
        "#@markdown\n",
        "\n",
        "#@markdown If you have multiple sequences, leave the <b>`single_sequence`</font></b> box unchecked and upload your file containing your sequences.\n",
        "\n",
        "#@markdown Format of your <b><font color='darkblue'>`.csv`</font></b>: Put all your target sequences in **One column called \"sequence\"**\n",
        "\n",
        "#@markdown Watch for a prompt to upload your <b><font color='darkblue'>`.csv`</font></b> file!!\n",
        "#@markdown\n",
        "\n",
        "jobname = \"test\" #@param {type: \"string\"}\n",
        "\n",
        "if single_sequence:\n",
        "  protein_seq = protein_seq\n",
        "else:\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  key = list(uploaded.keys())[0]\n",
        "  file_id = key\n",
        "  df = pd.read_csv(io.BytesIO(uploaded[key]),header=0)\n",
        "  df['sequence'] = df['sequence'].str.strip()\n",
        "  if list(df.columns) != ['sequence']:\n",
        "    print('ERROR: improperly formatted file')\n",
        "  sequences = df['sequence'].tolist()\n",
        "  protein_seq = sequences\n",
        "\n",
        "\n",
        "###Sliders\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout\n",
        "from IPython.display import display\n",
        "\n",
        "style = {'description_width': 'initial'}\n",
        "\n",
        "# Initial value for num_binders\n",
        "num_binders = 1\n",
        "\n",
        "# Initial values for top_k and peptide_length\n",
        "top_k = 3\n",
        "peptide_length = 15\n",
        "\n",
        "# Define the function that will save the selected value from the dropdown to num_binders\n",
        "def on_change(change):\n",
        "    global num_binders\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        num_binders = change['new']\n",
        "        print(f\"Updated num_binders: {num_binders}\")\n",
        "\n",
        "def update_values(change):\n",
        "    global top_k, peptide_length\n",
        "    top_k = top_k_slider.value\n",
        "    peptide_length = peptide_length_slider.value\n",
        "    print(f\"Updated Top K Value: {top_k}\")\n",
        "    print(f\"Updated Peptide Length: {peptide_length}\")\n",
        "\n",
        "# Create sliders for Top K Value and Peptide Length\n",
        "peptide_length_slider = widgets.IntSlider(value=15, min=3, max=50, step=1, description='Peptide Length:', style=style)\n",
        "top_k_slider = widgets.IntSlider(value=3, min=1, max=10, step=1, description='Top K Value:', style=style)\n",
        "\n",
        "# Display the sliders\n",
        "display(peptide_length_slider)\n",
        "print(\"Default value is 15\")\n",
        "display(top_k_slider)\n",
        "print(\"Default value is 3\")\n",
        "\n",
        "# Attach the update function to the sliders\n",
        "peptide_length_slider.observe(update_values, names='value')\n",
        "top_k_slider.observe(update_values, names='value')\n",
        "\n",
        "\n",
        "# Create a dropdown with options\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=[1, 2, 4, 8, 16, 32],\n",
        "    value=1,\n",
        "    description='Number of Binders',\n",
        "    disabled=False,\n",
        "    style=style\n",
        ")\n",
        "\n",
        "\n",
        "# Display the dropdown\n",
        "display(dropdown)\n",
        "\n",
        "# Attach the callback function to the dropdown\n",
        "dropdown.observe(on_change)"
      ],
      "metadata": {
        "id": "YtxfzxQi0KD6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Model\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "from torch.distributions.categorical import Categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the model and tokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ChatterjeeLab/PepMLM-650M\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"ChatterjeeLab/PepMLM-650M\").to(device)\n",
        "\n",
        "def compute_pseudo_perplexity(model, tokenizer, protein_seq, binder_seq):\n",
        "    '''\n",
        "    For alternative computation of PPL (in batch/matrix format), please check our github repo:\n",
        "    https://github.com/programmablebio/pepmlm/blob/main/scripts/generation.py\n",
        "    '''\n",
        "    sequence = protein_seq + binder_seq\n",
        "    tensor_input = tokenizer.encode(sequence, return_tensors='pt').to(model.device)\n",
        "    total_loss = 0\n",
        "\n",
        "    # Loop through each token in the binder sequence\n",
        "    for i in range(-len(binder_seq)-1, -1):\n",
        "        # Create a copy of the original tensor\n",
        "        masked_input = tensor_input.clone()\n",
        "\n",
        "        # Mask one token at a time\n",
        "        masked_input[0, i] = tokenizer.mask_token_id\n",
        "        # Create labels\n",
        "        labels = torch.full(tensor_input.shape, -100).to(model.device)\n",
        "        labels[0, i] = tensor_input[0, i]\n",
        "\n",
        "        # Get model prediction and loss\n",
        "        with torch.no_grad():\n",
        "            outputs = model(masked_input, labels=labels)\n",
        "            total_loss += outputs.loss.item()\n",
        "\n",
        "    # Calculate the average loss\n",
        "    avg_loss = total_loss / len(binder_seq)\n",
        "\n",
        "    # Calculate pseudo perplexity\n",
        "    pseudo_perplexity = np.exp(avg_loss)\n",
        "    return pseudo_perplexity\n",
        "\n",
        "\n",
        "def generate_peptide_for_single_sequence(protein_seq, peptide_length = 15, top_k = 3, num_binders = 4):\n",
        "\n",
        "    peptide_length = int(peptide_length)\n",
        "    top_k = int(top_k)\n",
        "    num_binders = int(num_binders)\n",
        "\n",
        "    binders_with_ppl = []\n",
        "\n",
        "    for _ in range(num_binders):\n",
        "        # Generate binder\n",
        "        masked_peptide = '<mask>' * peptide_length\n",
        "        input_sequence = protein_seq + masked_peptide\n",
        "        inputs = tokenizer(input_sequence, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits\n",
        "        mask_token_indices = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "        logits_at_masks = logits[0, mask_token_indices]\n",
        "\n",
        "        # Apply top-k sampling\n",
        "        top_k_logits, top_k_indices = logits_at_masks.topk(top_k, dim=-1)\n",
        "        probabilities = torch.nn.functional.softmax(top_k_logits, dim=-1)\n",
        "        predicted_indices = Categorical(probabilities).sample()\n",
        "        predicted_token_ids = top_k_indices.gather(-1, predicted_indices.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        generated_binder = tokenizer.decode(predicted_token_ids, skip_special_tokens=True).replace(' ', '')\n",
        "\n",
        "        # Compute PPL for the generated binder\n",
        "        ppl_value = compute_pseudo_perplexity(model, tokenizer, protein_seq, generated_binder)\n",
        "\n",
        "        # Add the generated binder and its PPL to the results list\n",
        "        binders_with_ppl.append([generated_binder, ppl_value])\n",
        "\n",
        "    return binders_with_ppl\n",
        "\n",
        "def generate_peptide(input_seqs, peptide_length=15, top_k=3, num_binders=4):\n",
        "    if isinstance(input_seqs, str):  # Single sequence\n",
        "        binders = generate_peptide_for_single_sequence(input_seqs, peptide_length, top_k, num_binders)\n",
        "        return pd.DataFrame(binders, columns=['Binder', 'Pseudo Perplexity'])\n",
        "\n",
        "    elif isinstance(input_seqs, list):  # List of sequences\n",
        "        results = []\n",
        "        for seq in input_seqs:\n",
        "            binders = generate_peptide_for_single_sequence(seq, peptide_length, top_k, num_binders)\n",
        "            for binder, ppl in binders:\n",
        "                results.append([seq, binder, ppl])\n",
        "        return pd.DataFrame(results, columns=['Input Sequence', 'Binder', 'Pseudo Perplexity'])"
      ],
      "metadata": {
        "id": "5aQbcmqQhkFF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Peptides\n",
        "peptide_df = generate_peptide(protein_seq, peptide_length, top_k, num_binders)\n",
        "peptide_df"
      ],
      "metadata": {
        "id": "VtfbXYndhyle",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Results\n",
        "from google.colab import files\n",
        "\n",
        "# Assuming peptide_df is already defined and filled with data\n",
        "peptide_df.to_csv(f\"{jobname}.csv\", index=False)  # Save the dataframe to a csv file\n",
        "\n",
        "# Use colab's files.download method to trigger a file download in the browser\n",
        "files.download(f\"{jobname}.csv\")\n"
      ],
      "metadata": {
        "id": "69ilpjM9vDjL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "54d74607-a744-4dd5-da0c-699c59b5baae",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5d0b6203-f57d-4630-a6de-407d03f5f4be\", \"test.csv\", 7911)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}